{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYe-1iFbo3dQ"
      },
      "source": [
        "# Process dataset for use with deep learning segmentation network\n",
        "> A guide for processing raster data and labels into ML-ready format for use with a deep-learning based semantic segmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wLP8n9tvVwD"
      },
      "source": [
        "### Setup Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAc6COLJvsXJ"
      },
      "source": [
        "```{admonition} **Version control**\n",
        "Colab updates without warning to users, which can cause notebooks to break. Therefore, we are pinning library versions.\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lYMOkBeaeuoV"
      },
      "outputs": [],
      "source": [
        "# install required libraries\n",
        "!pip install -q rasterio==1.2.10\n",
        "!pip install -q geopandas==0.10.2\n",
        "!pip install -q radiant_mlhub # for dataset access, see: https://mlhub.earth/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-hVmWq9Okpl"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import os, glob, functools, fnmatch, io, shutil, tarfile, json\n",
        "from zipfile import ZipFile\n",
        "from itertools import product\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "from fractions import Fraction  \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import rasterio\n",
        "from rasterio.merge import merge\n",
        "from rasterio.plot import show\n",
        "from rasterio import features, mask, windows\n",
        "\n",
        "import geopandas as gpd\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import cv2\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from radiant_mlhub import Dataset, client, get_session, Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giJXbs16glT1"
      },
      "outputs": [],
      "source": [
        "# configure Radiant Earth MLHub access\n",
        "!mlhub configure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx4zlZ7SgmO_"
      },
      "outputs": [],
      "source": [
        "# Mount google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apZ0WgLYkgnO"
      },
      "outputs": [],
      "source": [
        "# set your root directory and tiled data folders\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    root_dir = '/content/gdrive/My Drive/tf-eo-devseed/' \n",
        "    workshop_dir = '/content/gdrive/My Drive/tf-eo-devseed-workshop'\n",
        "    dirs = [root_dir, workshop_dir]\n",
        "    for d in dirs:\n",
        "        if not os.path.exists(d):\n",
        "            os.makedirs(d)\n",
        "    print('Running on Colab')\n",
        "else:\n",
        "    root_dir = os.path.abspath(\"./data/tf-eo-devseed\")\n",
        "    workshop_dir = os.path.abspath('./tf-eo-devseed-workshop')\n",
        "    print(f'Not running on Colab, data needs to be downloaded locally at {os.path.abspath(root_dir)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvMr1cQqrw-a"
      },
      "outputs": [],
      "source": [
        "%cd $root_dir "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1JXQbTFlJYZ"
      },
      "source": [
        "#### Enabling GPU\n",
        "```{Tip}\n",
        "This notebook can utilize a GPU and works better if you use one. Hopefully this notebook is using a GPU, and we can check with the following code.\n",
        "\n",
        "If it's not using a GPU you can change your session/notebook to use a GPU. See [Instructions](https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=sXnDmXR7RDr2).\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvlhp4RRlOMy"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke_AfyJDgvt1"
      },
      "source": [
        "## Access the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8EhCYu8EfhY"
      },
      "source": [
        "We will use a crop type classification dataset from Radiant Earth MLHub: https://mlhub.earth/data/dlr_fusion_competition_germany"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzKvvoeig1MT",
        "outputId": "ca8b264b-452e-47df-9c2d-96def995525d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dlr_fusion_competition_germany_train_source_planet\n",
            "dlr_fusion_competition_germany_train_source_planet_5day\n",
            "dlr_fusion_competition_germany_train_source_sentinel_1\n",
            "dlr_fusion_competition_germany_train_source_sentinel_2\n",
            "dlr_fusion_competition_germany_test_source_planet\n",
            "dlr_fusion_competition_germany_test_source_planet_5day\n",
            "dlr_fusion_competition_germany_test_source_sentinel_1\n",
            "dlr_fusion_competition_germany_test_source_sentinel_2\n",
            "dlr_fusion_competition_germany_train_labels\n",
            "dlr_fusion_competition_germany_test_labels\n"
          ]
        }
      ],
      "source": [
        "ds = Dataset.fetch('dlr_fusion_competition_germany')\n",
        "for c in ds.collections:\n",
        "    print(c.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_0Kw9f9kg5wK"
      },
      "outputs": [],
      "source": [
        "collections = [\n",
        "    'dlr_fusion_competition_germany_train_source_planet_5day',\n",
        "    'dlr_fusion_competition_germany_test_source_planet_5day',\n",
        "    'dlr_fusion_competition_germany_train_labels',\n",
        "    'dlr_fusion_competition_germany_test_labels'\n",
        "]\n",
        "\n",
        "def download(collection_id):\n",
        "    print(f'Downloading {collection_id}...')\n",
        "    collection = Collection.fetch(collection_id)\n",
        "    path = collection.download('.')\n",
        "    tar = tarfile.open(path, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "    os.remove(path)\n",
        "    \n",
        "def resolve_path(base, path):\n",
        "    return Path(os.path.join(base, path)).resolve()\n",
        "    \n",
        "def load_df(collection_id):\n",
        "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
        "    rows = []\n",
        "    item_links = []\n",
        "    for link in collection['links']:\n",
        "        if link['rel'] != 'item':\n",
        "            continue\n",
        "        item_links.append(link['href'])\n",
        "    for item_link in item_links:\n",
        "        item_path = f'{collection_id}/{item_link}'\n",
        "        current_path = os.path.dirname(item_path)\n",
        "        item = json.load(open(item_path, 'r'))\n",
        "        tile_id = item['id'].split('_')[-1]\n",
        "        for asset_key, asset in item['assets'].items():\n",
        "            rows.append([\n",
        "                tile_id,\n",
        "                None,\n",
        "                None,\n",
        "                asset_key,\n",
        "                str(resolve_path(current_path, asset['href']))\n",
        "            ])\n",
        "            \n",
        "        for link in item['links']:\n",
        "            if link['rel'] != 'source':\n",
        "                continue\n",
        "            link_path = resolve_path(current_path, link['href'])\n",
        "            source_path = os.path.dirname(link_path)\n",
        "            try:\n",
        "                source_item = json.load(open(link_path, 'r'))\n",
        "            except FileNotFoundError:\n",
        "                continue\n",
        "            datetime = source_item['properties']['datetime']\n",
        "            satellite_platform = source_item['collection'].split('_')[-1]\n",
        "            for asset_key, asset in source_item['assets'].items():\n",
        "                rows.append([\n",
        "                    tile_id,\n",
        "                    datetime,\n",
        "                    satellite_platform,\n",
        "                    asset_key,\n",
        "                    str(resolve_path(source_path, asset['href']))\n",
        "                ])\n",
        "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
        "\n",
        "for c in collections:\n",
        "    download(c)\n",
        "\n",
        "train_df = load_df('dlr_fusion_competition_germany_train_labels')\n",
        "test_df = load_df('dlr_fusion_competition_germany_test_labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvYIbninPlj_"
      },
      "source": [
        "### Check out the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTR5MsFWPi0W"
      },
      "source": [
        "Class names and identifiers extracted from the documentation provided here: https://radiantearth.blob.core.windows.net/mlhub/esa-food-security-challenge/Crops_GT_Brandenburg_Doc.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXXkNPAljTbp",
        "outputId": "5ea86c1a-aa53-4986-8807-d6ad2baeaf5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    class_names  class_ids\n",
            "0    Background          0\n",
            "1         Wheat          1\n",
            "2           Rye          2\n",
            "3        Barley          3\n",
            "4          Oats          4\n",
            "5          Corn          5\n",
            "6     Oil Seeds          6\n",
            "7    Root Crops          7\n",
            "8       Meadows          8\n",
            "9  Forage Crops          9\n",
            "classes in labels geojson:  [1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "# Read the classes\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "data = {'class_names':  ['Background', 'Wheat', 'Rye', 'Barley', 'Oats', 'Corn', 'Oil Seeds', 'Root Crops', 'Meadows', 'Forage Crops'],\n",
        "        'class_ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "        }\n",
        "\n",
        "classes = pd.DataFrame(data)\n",
        "print(classes) \n",
        "\n",
        "classes.to_csv('lulc_classes.csv')\n",
        "\n",
        "# Let's check the class labels\n",
        "labels_geo = gpd.read_file('dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/labels.geojson')\n",
        "classes = labels_geo.crop_id.unique()\n",
        "classes.sort()\n",
        "print(\"classes in labels geojson: \", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li-uVZicOkpp"
      },
      "source": [
        "## Raster processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ0nu_c5vjAW"
      },
      "source": [
        "```{admonition} **IMPORTANT**\n",
        "This section contains helper functions for processing the raw raster composites.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qiTudEkOkpu"
      },
      "source": [
        "Get the Planet fusion images. \n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2XwsssCkcAlY"
      },
      "outputs": [],
      "source": [
        "def raster_read(raster_dir):\n",
        "    print(raster_dir)\n",
        "\n",
        "    # Read band metadata and arrays\n",
        "    # metadata\n",
        "    rgbn = rasterio.open(os.path.join(raster_dir,'sr.tif')) #rgbn\n",
        "    rgbn_src = rgbn\n",
        "    target_crs = rgbn_src.crs\n",
        "    print(\"rgbn: \", rgbn)\n",
        "\n",
        "    # arrays\n",
        "    # Read and re-scale the original 16 bit image to 8 bit.\n",
        "    scale = True\n",
        "    if scale:\n",
        "      rgbn_norm = cv2.normalize(rgbn.read(), None, 0, 255, cv2.NORM_MINMAX)\n",
        "      rgbn_norm_out=rasterio.open(os.path.join(raster_dir,'sr_byte_scaled.tif'), 'w', driver='Gtiff',\n",
        "                                  width=rgbn_src.width, height=rgbn_src.height,\n",
        "                                  count=4,\n",
        "                                  crs=rgbn_src.crs,\n",
        "                                  transform=rgbn_src.transform,\n",
        "                                  dtype='uint8')\n",
        "\n",
        "      rgbn_norm_out.write(rgbn_norm)\n",
        "      rgbn_norm_out.close()\n",
        "      rgbn = rasterio.open(os.path.join(raster_dir,'sr_byte_scaled.tif')) #rgbn\n",
        "    else:\n",
        "      rgbn = rasterio.open(os.path.join(raster_dir,'sr_byte_scaled.tif')) #rgbn\n",
        "    print(\"Scaled to 8bit.\")\n",
        "    return raster_dir, rgbn, rgbn_src, target_crs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrSrlgEoM7f6"
      },
      "source": [
        "Calculate relevant spectral indices\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOvn07MEOkpz"
      },
      "source": [
        "**WDRVI**: Wide Dynamic Range Vegetation Index \\\n",
        "**NDVI**: Normalized Difference Vegetation Index \\\n",
        "**SI**: Shadow Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BfT55Ypmc8Pz"
      },
      "outputs": [],
      "source": [
        "# calculate spectral indices and concatenate them into one 3 channel image\n",
        "def indexnormstack(red, green, blue, nir):\n",
        "\n",
        "    def WDRVIcalc(nir, red): \n",
        "        a = 0.15\n",
        "        wdrvi =  (a * nir-red)/(a * nir+red)\n",
        "        return wdrvi\n",
        "\n",
        "    def NPCRIcalc(red,blue):\n",
        "        npcri =  (red-blue)/(red+blue)\n",
        "        return npcri\n",
        "\n",
        "    def NDVIcalc(nir, red): \n",
        "        ndvi = (nir - red) / (nir  + red + 1e-5) \n",
        "        return ndvi\n",
        "\n",
        "\n",
        "    def SIcalc(red, green, blue):\n",
        "        expo = Fraction('1/3') \n",
        "        si = (((1-red)*(1-green)*(1-blue))**expo)\n",
        "        return si\n",
        "\n",
        "    def norm(arr):\n",
        "        scaler = MinMaxScaler(feature_range=(0, 255))\n",
        "        scaler = scaler.fit(arr)\n",
        "        arr_norm = scaler.transform(arr)\n",
        "        # Checking reconstruction\n",
        "        #arr_norm = scaler.inverse_transform(arr_norm)\n",
        "\n",
        "        return arr_norm\n",
        "\n",
        "    wdrvi = WDRVIcalc(nir,red) \n",
        "\n",
        "    #npcri = NPCRIcalc(red,blue)\n",
        "\n",
        "    ndi = NDVIcalc(nir, red)\n",
        "\n",
        "    si = SIcalc(red,green,blue) \n",
        "\n",
        "    print(\"wdrvi: \", wdrvi.min(), wdrvi.max(), \"ndi: \", ndi.min(), ndi.max(), \"si: \", si.min(), si.max())\n",
        "\n",
        "    wdrvi = norm(wdrvi)\n",
        "    ndi = norm(ndi)\n",
        "    si = norm(si)\n",
        "\n",
        "    index_stack = np.dstack((wdrvi, ndi, si))\n",
        "\n",
        "    return index_stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C0QymeoqX1y"
      },
      "source": [
        "Stack bands of interest.\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sBzBqXgyqVOv"
      },
      "outputs": [],
      "source": [
        "def bandstack(red, green, blue, nir):\n",
        "\n",
        "    stack = np.dstack((red, green, blue))\n",
        "\n",
        "    return stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(Optional) color correction for the optical composite. \n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to increase the brightness in an image\n",
        "def change_brightness(img, value=30):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    v = cv2.add(v,value)\n",
        "    v[v > 255] = 255\n",
        "    v[v < 0] = 0\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrPYKwumNAIn"
      },
      "source": [
        "If you are rasterizing the labels from a vector file (e.g. GeoJSON or Shapefile).\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qupnU_awOkp8"
      },
      "source": [
        "Read label shapefile into geopandas dataframe, check for invalid geometries and set to local CRS. Then, rasterize the labeled polygons using the metadata from one of the grayscale band images. In this function, `geo_1` is used when there are two vector files used for labeling. The latter is given preference over the former because it overwrites when intersections occur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wcTdSrPIdC8_"
      },
      "outputs": [],
      "source": [
        "def label(geos, labels_src):\n",
        "    geo_0 = gpd.read_file(geos[0])\n",
        "    # check for and remove invalid geometries\n",
        "    geo_0 = geo_0.loc[geo_0.is_valid]\n",
        "    # reproject training data into local coordinate reference system\n",
        "    geo_0 = geo_0.to_crs(crs={'init': target_crs})\n",
        "    #convert the class identifier column to type integer\n",
        "    geo_0['landcover_int']  = geo_0.crop_id.astype(int)\n",
        "    # pair the geometries and their integer class values\n",
        "    shapes_0 = ((geom,value) for geom, value in zip(geo_0.geometry, geo_0.landcover_int)) \n",
        "    if len(geos) > 1:\n",
        "      geo_1 = gpd.read_file(geos[1])\n",
        "      geo_1 = geo_1.loc[geo_1.is_valid]\n",
        "      geo_1 = geo_1.to_crs(crs={'init': target_crs})\n",
        "      geo_1['landcover_int']  = geo_1.crop_id.astype(int)\n",
        "      shapes_1 = ((geom,value) for geom, value in zip(geo_1.geometry, geo_1.landcover_int)) \n",
        "    else:\n",
        "      print(\"Only one source of vector labels.\") #continue\n",
        "\n",
        "    # get the metadata (height, width, channels, transform, CRS) to use in constructing the labeled image array\n",
        "    labels_src_prf = labels_src.profile\n",
        "    # construct a blank array from the metadata and burn the labels in\n",
        "    labels = features.rasterize(shapes=shapes_0, out_shape=(labels_src_prf['height'], labels_src_prf['width']), fill=0, all_touched=True, transform=labels_src_prf['transform'], dtype=labels_src_prf['dtype'])\n",
        "    if len(geos) > 1:\n",
        "      labels = features.rasterize(shapes=shapes_1, fill=0, all_touched=True, out=labels, transform=labels_src_prf['transform'])\n",
        "    else:\n",
        "      print(\"Only one source of vector labels.\") #continue\n",
        "\n",
        "    print(\"Values in labeled image: \", np.unique(labels))\n",
        "\n",
        "\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzJhiyrKYFT_"
      },
      "source": [
        "Write the processed rasters to file.\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U-OBN1ERdjTx"
      },
      "outputs": [],
      "source": [
        "def save_images(raster_dir, rgb_norm, stack, index_stack, labels, rgb_src):\n",
        "\n",
        "    stack_computed = True # change to True if using the stack helper function above\n",
        "\n",
        "    if stack_computed:\n",
        "      stack_t = stack.transpose(2,0,1)\n",
        "    else:\n",
        "      stack_t = stack\n",
        "\n",
        "    stack_out=rasterio.open(os.path.join(raster_dir,'stack.tif'), 'w', driver='Gtiff',\n",
        "                              width=rgb_src.width, height=rgb_src.height,\n",
        "                              count=3,\n",
        "                              crs=rgb_src.crs,\n",
        "                              transform=rgb_src.transform,\n",
        "                              dtype='uint8')\n",
        "\n",
        "    stack_out.write(stack_t)\n",
        "\n",
        "    indices_computed = True # change to True if using the index helper function above\n",
        "    if indices_computed:\n",
        "      index_stack_t = index_stack.transpose(2,0,1)\n",
        "    else:\n",
        "      index_stack_t = index_stack\n",
        "\n",
        "    index_stack_out=rasterio.open(os.path.join(raster_dir,'index_stack.tif'), 'w', driver='Gtiff',\n",
        "                              width=rgb_src.width, height=rgb_src.height,\n",
        "                              count=3,\n",
        "                              crs=rgb_src.crs,\n",
        "                              transform=rgb_src.transform,\n",
        "                              dtype='uint8')\n",
        "\n",
        "    index_stack_out.write(index_stack_t)\n",
        "    #index_stack_out.close()\n",
        "\n",
        "    labels = labels.astype(np.uint8)\n",
        "    labels_out=rasterio.open(os.path.join(raster_dir,'labels.tif'), 'w', driver='Gtiff',\n",
        "                              width=rgb_src.width, height=rgb_src.height,\n",
        "                              count=1,\n",
        "                              crs=rgb_src.crs,\n",
        "                              transform=rgb_src.transform,\n",
        "                              dtype='uint8')\n",
        "\n",
        "    labels_out.write(labels, 1)\n",
        "    #labels_out.close()\n",
        "\n",
        "    print(\"written\")\n",
        "\n",
        "    return os.path.join(raster_dir,'stack.tif'), os.path.join(raster_dir,'index_stack.tif'), os.path.join(raster_dir,'labels.tif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1sCrGc1OkqF"
      },
      "source": [
        "Now let's divide the optical/index stack and labeled image into 224x224 pixel tiles.\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VQKfv68HeXym"
      },
      "outputs": [],
      "source": [
        "def tile(index_stack, labels, prefix, width, height, raster_dir, output_dir, brighten=False):\n",
        "    tiles_dir = os.path.join(output_dir,'tiled/')\n",
        "    img_dir = os.path.join(output_dir,'tiled/stacks_brightened/')\n",
        "    label_dir = os.path.join(output_dir,'tiled/labels/')\n",
        "    dirs = [tiles_dir, img_dir, label_dir]\n",
        "    for d in dirs:\n",
        "        if not os.path.exists(d):\n",
        "            os.makedirs(d)\n",
        "\n",
        "    def get_tiles(ds):\n",
        "        # get number of rows and columns (pixels) in the entire input image\n",
        "        nols, nrows = ds.meta['width'], ds.meta['height']\n",
        "        # get the grid from which tiles will be made \n",
        "        offsets = product(range(0, nols, width), range(0, nrows, height))\n",
        "        # get the window of the entire input image\n",
        "        big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
        "        # tile the big window by mini-windows per grid cell\n",
        "        for col_off, row_off in offsets:\n",
        "            window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
        "            transform = windows.transform(window, ds.transform)\n",
        "            yield window, transform\n",
        "\n",
        "    tile_width, tile_height = width, height\n",
        "\n",
        "    def crop(inpath, outpath, c):\n",
        "        # read input image\n",
        "        image = rasterio.open(inpath)\n",
        "        # get the metadata \n",
        "        meta = image.meta.copy()\n",
        "        print(\"meta: \", meta)\n",
        "        # set the number of channels to 3 or 1, depending on if its the index image or labels image\n",
        "        meta['count'] = int(c)\n",
        "        # set the tile output file format to PNG (saves spatial metadata unlike JPG)\n",
        "        meta['driver']='PNG'\n",
        "        meta['dtype']='uint8'\n",
        "        # tile the input image by the mini-windows\n",
        "        i = 0\n",
        "        for window, transform in get_tiles(image):\n",
        "            meta['transform'] = transform\n",
        "            meta['width'], meta['height'] = window.width, window.height\n",
        "            outfile = os.path.join(outpath,\"tile_%s_%s.png\" % (prefix, str(i)))\n",
        "            with rasterio.open(outfile, 'w', **meta) as outds:\n",
        "                if brighten:\n",
        "                  imw = image.read(window=window)\n",
        "                  imw = imw.transpose(1,2,0)\n",
        "                  imwb = change_brightness(imw, value=50)\n",
        "                  imwb = imwb.transpose(2,0,1)\n",
        "                  outds.write(imwb)\n",
        "                else:\n",
        "                  outds.write(image.read(window=window))\n",
        "            i = i+1\n",
        "\n",
        "    def process_tiles(index_flag):\n",
        "        # tile the input images, when index_flag == True, we are tiling the spectral index image, \n",
        "        # when False we are tiling the labels image\n",
        "        if index_flag==True:\n",
        "            inpath = os.path.join(raster_dir,'stack.tif')\n",
        "            outpath=img_dir\n",
        "            crop(inpath, outpath, 3)\n",
        "        else:\n",
        "            inpath = os.path.join(raster_dir,'labels.tif')\n",
        "            outpath=label_dir\n",
        "            crop(inpath, outpath, 1)\n",
        "\n",
        "    process_tiles(index_flag=True) # tile stack\n",
        "    process_tiles(index_flag=False) # tile labels\n",
        "    return tiles_dir, img_dir, label_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7IN7jjXA4G3"
      },
      "source": [
        "Run the image processing workflow.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "&#9888 <b>Long running code</b> &#9888 Google Drive based workflows can incur timeouts and latency issues. If this happens, try running the affected cell again. Having a VM with a mounted SSD would be a good start to solving these associated latency problems incurred from I/O of data hosted in Google Drive.\n",
        "</div>\n",
        "\n",
        "<div>&#8681</div> \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HMPL7-4FfWIO"
      },
      "outputs": [],
      "source": [
        "train_images_dir = 'dlr_fusion_competition_germany_train_source_planet_5day'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ObEvIpThO9K",
        "outputId": "7e97854b-46cb-47b3-bdbd-6cbcffb4cbc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/tf-eo-devseed/dlr_fusion_competition_germany_train_source_planet_5day\n"
          ]
        }
      ],
      "source": [
        "%cd $train_images_dir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E9m2ES7Ufr_V"
      },
      "outputs": [],
      "source": [
        "train_images_dirs = [f.path for f in os.scandir('./') if f.is_dir()]\n",
        "train_images_dirs = [x.replace('./', '') if type(x) is str else x for x in train_images_dirs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oszSjT7zhgYQ",
        "outputId": "85446845-e8c4-4d0f-bcc1-fa669ead9a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/tf-eo-devseed\n"
          ]
        }
      ],
      "source": [
        "%cd $root_dir "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAEeKxGiegqd"
      },
      "outputs": [],
      "source": [
        "process = True\n",
        "if process:\n",
        "  raster_out_dir = os.path.join(root_dir,'rasters/')\n",
        "  if not os.path.exists(raster_out_dir):\n",
        "    os.makedirs(raster_out_dir)\n",
        "\n",
        "  # If you want to write the files out to your personal drive, set write_out = True, but I recommend trying \n",
        "  # that in your free time because it takes about 2 hours or more for all composites.\n",
        "\n",
        "  write_out = True #False\n",
        "  if write_out == True:\n",
        "    for train_image_dir in train_images_dirs: #[0:1]:\n",
        "      # read the rasters and scale to 8bit\n",
        "      print(\"reading and scaling rasters...\")\n",
        "      raster_dir, rgbn, rgbn_src, target_crs = raster_read(os.path.join(train_images_dir,train_image_dir))\n",
        "\n",
        "      # Calculate indices and combine the indices into one single 3 channel image\n",
        "      print(\"calculating spectral indices...\")\n",
        "      index_stack = indexnormstack(rgbn.read(3), rgbn.read(2), rgbn.read(1), rgbn.read(4))\n",
        "\n",
        "      # Stack channels of interest (RGB) into one single 3 channel image\n",
        "      print(\"Stacking channels of interest...\")\n",
        "      stack = bandstack(rgbn.read(3), rgbn.read(2), rgbn.read(1), rgbn.read(4))\n",
        "\n",
        "      # Color correct the RGB image\n",
        "      print(\"Color correcting a RGB image...\")\n",
        "      cc_stack = change_brightness(stack)\n",
        "\n",
        "      # Rasterize labels\n",
        "      labels = label([os.path.join(root_dir,'dlr_fusion_competition_germany_train_labels/dlr_fusion_competition_germany_train_labels_33N_18E_242N/labels.geojson')], rgbn_src)\n",
        "\n",
        "      # Save index stack and labels to geotiff\n",
        "      print(\"writing scaled rasters and labels to file...\")\n",
        "      stack_file, index_stack_file, labels_file = save_images(raster_dir, rgbn, cc_stack, index_stack, labels, rgbn_src)\n",
        "\n",
        "      # Tile images into 224x224\n",
        "      print(\"tiling the indices and labels...\")\n",
        "      tiles_dir, img_dir, label_dir = tile(stack, labels, str(train_image_dir), 224, 224, raster_dir, raster_out_dir, brighten=False)\n",
        "  else:\n",
        "    print(\"Not writing to file; using data in shared drive.\")\n",
        "\n",
        "else:\n",
        "  print(\"Using pre-processed dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxVDL_DVmICI"
      },
      "source": [
        "## Read the data into memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CYrfjF2mbod"
      },
      "source": [
        "#### Getting set up with the data\n",
        "\n",
        "```{important}\n",
        "The tiled imagery will be available at the following path that is accessible with the google.colab `drive` module: `'/content/gdrive/My Drive/tf-eo-devseed/'`\n",
        "```\n",
        "\n",
        "We'll be working with the following folders and files in the `tf-eo-devseed` folder:\n",
        "```\n",
        "tf-eo-devseed/\n",
        "├── stacks/\n",
        "├── stacks_brightened/\n",
        "├── indices/\n",
        "├── labels/\n",
        "├── background_list_train.txt\n",
        "├── train_list_clean.txt\n",
        "└── lulc_classes.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwLICWXjmG_"
      },
      "source": [
        "\n",
        "\n",
        "Get lists of image and label tile pairs for training and testing.\n",
        "<div>&#8681</div> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDry5BEfl-gG"
      },
      "outputs": [],
      "source": [
        "def get_train_test_lists(imdir, lbldir):\n",
        "  imgs = glob.glob(os.path.join(imdir,\"*.png\"))\n",
        "  #print(imgs[0:1])\n",
        "  dset_list = []\n",
        "  for img in imgs:\n",
        "    filename_split = os.path.splitext(img) \n",
        "    filename_zero, fileext = filename_split \n",
        "    basename = os.path.basename(filename_zero) \n",
        "    dset_list.append(basename)\n",
        "\n",
        "  x_filenames = []\n",
        "  y_filenames = []\n",
        "  for img_id in dset_list:\n",
        "    x_filenames.append(os.path.join(imdir, \"{}.png\".format(img_id)))\n",
        "    y_filenames.append(os.path.join(lbldir, \"{}.png\".format(img_id)))\n",
        "\n",
        "  print(\"number of images: \", len(dset_list))\n",
        "  return dset_list, x_filenames, y_filenames\n",
        "\n",
        "train_list, x_train_filenames, y_train_filenames = get_train_test_lists(img_dir, label_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXlxicu6mskP"
      },
      "source": [
        "Check for the proportion of background tiles. This takes a while. So after running this once, you can skip by loading from saved results.\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDXcxrFZmRP_"
      },
      "outputs": [],
      "source": [
        "skip = False\n",
        "\n",
        "if not skip:\n",
        "  background_list_train = []\n",
        "  for i in train_list: \n",
        "      # read in each labeled images\n",
        "      # print(os.path.join(label_dir,\"{}.png\".format(i))) \n",
        "      img = np.array(Image.open(os.path.join(label_dir,\"{}.png\".format(i))))  \n",
        "      # check if no values in image are greater than zero (background value)\n",
        "      if img.max()==0:\n",
        "          background_list_train.append(i)\n",
        "\n",
        "  print(\"Number of background images: \", len(background_list_train))\n",
        "\n",
        "  with open(os.path.join(root_dir,'background_list_train.txt'), 'w') as f:\n",
        "    for item in background_list_train:\n",
        "        f.write(\"%s\\n\" % item)\n",
        "\n",
        "else:\n",
        "  background_list_train = [line.strip() for line in open(\"background_list_train.txt\", 'r')]\n",
        "  print(\"Number of background images: \", len(background_list_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFFdmtqOmwHU"
      },
      "source": [
        "\n",
        "\n",
        "We will keep only 10% of the total. Too many background tiles can cause a form of class imbalance.\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztCpq8ZDmZ57"
      },
      "outputs": [],
      "source": [
        "background_removal = len(background_list_train) * 0.9\n",
        "train_list_clean = [y for y in train_list if y not in background_list_train[0:int(background_removal)]]\n",
        "\n",
        "x_train_filenames = []\n",
        "y_train_filenames = []\n",
        "\n",
        "for i, img_id in zip(tqdm(range(len(train_list_clean))), train_list_clean):\n",
        "  pass \n",
        "  x_train_filenames.append(os.path.join(img_dir, \"{}.png\".format(img_id)))\n",
        "  y_train_filenames.append(os.path.join(label_dir, \"{}.png\".format(img_id)))\n",
        "\n",
        "print(\"Number of background tiles: \", background_removal)\n",
        "print(\"Remaining number of tiles after 90% background removal: \", len(train_list_clean))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TyHAvb_OkqT"
      },
      "source": [
        "Now that we have our set of files we want to use for developing our model, we need to split them into three sets: \n",
        "* the training set for the model to learn from\n",
        "* the validation set that allows us to evaluate models and make decisions to change models\n",
        "* and the test set that we will use to communicate the results of the best performing model (as determined by the validation set)\n",
        "\n",
        "We will split index tiles and label tiles into train, validation and test sets: 70%, 20% and 10%, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3tOcxtwOkqU"
      },
      "outputs": [],
      "source": [
        "x_train_filenames, x_val_filenames, y_train_filenames, y_val_filenames = train_test_split(x_train_filenames, y_train_filenames, test_size=0.3, random_state=42)\n",
        "x_val_filenames, x_test_filenames, y_val_filenames, y_test_filenames = train_test_split(x_val_filenames, y_val_filenames, test_size=0.33, random_state=42)\n",
        "\n",
        "num_train_examples = len(x_train_filenames)\n",
        "num_val_examples = len(x_val_filenames)\n",
        "num_test_examples = len(x_test_filenames)\n",
        "\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of validation examples: {}\".format(num_val_examples))\n",
        "print(\"Number of test examples: {}\".format(num_test_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAC9wKRb8pYd"
      },
      "source": [
        "```{warning} **Long running cell** \\\n",
        "The code below checks for values in train, val, and test partitions. We won't run this since it takes over 10 minutes on colab due to slow IO.\n",
        "``` \n",
        "<div>&#8681</div> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgjdgsQkm72G"
      },
      "outputs": [],
      "source": [
        "vals_train = []\n",
        "vals_val = []\n",
        "vals_test = []\n",
        "\n",
        "def get_vals_in_partition(partition_list, x_filenames, y_filenames):\n",
        "  for x,y,i in zip(x_filenames, y_filenames, tqdm(range(len(y_filenames)))):\n",
        "      pass \n",
        "      try:\n",
        "        img = np.array(Image.open(y)) \n",
        "        vals = np.unique(img)\n",
        "        partition_list.append(vals)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "def flatten(partition_list):\n",
        "    return [item for sublist in partition_list for item in sublist]\n",
        "\n",
        "get_vals_in_partition(vals_train, x_train_filenames, y_train_filenames)\n",
        "get_vals_in_partition(vals_val, x_val_filenames, y_val_filenames)\n",
        "get_vals_in_partition(vals_test, x_test_filenames, y_test_filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Zf4TTpnBax",
        "outputId": "ce340e3c-5a7c-4538-a7a3-54e8b989fc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Values in training partition:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "Values in validation partition:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "Values in test partition:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ],
      "source": [
        "print(\"Values in training partition: \", set(flatten(vals_train)))\n",
        "print(\"Values in validation partition: \", set(flatten(vals_val)))\n",
        "print(\"Values in test partition: \", set(flatten(vals_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRfSZbtUOkqW"
      },
      "source": [
        "### Visualize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGSBP06FI1DR"
      },
      "source": [
        "```{warning} **Long running cell** \\\n",
        "The code below loads foreground examples randomly. \n",
        "```\n",
        "<div>&#8681</div> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6obhxldonIaE"
      },
      "outputs": [],
      "source": [
        "display_num = 3\n",
        "\n",
        "background_list_train = [line.strip() for line in open(\"background_list_train.txt\", 'r')]\n",
        "\n",
        "# select only for tiles with foreground labels present\n",
        "foreground_list_x = []\n",
        "foreground_list_y = []\n",
        "for x,y in zip(x_train_filenames, y_train_filenames): \n",
        "    try:\n",
        "      filename_split = os.path.splitext(y) \n",
        "      filename_zero, fileext = filename_split \n",
        "      basename = os.path.basename(filename_zero) \n",
        "      if basename not in background_list_train:\n",
        "        foreground_list_x.append(x)\n",
        "        foreground_list_y.append(y)\n",
        "      else:\n",
        "        continue\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "num_foreground_examples = len(foreground_list_y)\n",
        "\n",
        "# randomlize the choice of image and label pairs\n",
        "r_choices = np.random.choice(num_foreground_examples, display_num)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "for i in range(0, display_num * 2, 2):\n",
        "  img_num = r_choices[i // 2]\n",
        "  img_num = i // 2\n",
        "  x_pathname = foreground_list_x[img_num]\n",
        "  y_pathname = foreground_list_y[img_num]\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 1)\n",
        "  plt.imshow(mpimg.imread(x_pathname))\n",
        "  plt.title(\"Original Image\")\n",
        "  \n",
        "  example_labels = Image.open(y_pathname)\n",
        "  label_vals = np.unique(np.array(example_labels))\n",
        "  \n",
        "  plt.subplot(display_num, 2, i + 2)\n",
        "  plt.imshow(example_labels)\n",
        "  plt.title(\"Masked Image\")  \n",
        "  \n",
        "plt.suptitle(\"Examples of Images and their Masks\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of Lesson2b_prep_data_ML_segmentation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
